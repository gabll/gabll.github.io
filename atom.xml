<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[gabll blog]]></title>
  <link href="http://gabll.github.io/atom.xml" rel="self"/>
  <link href="http://gabll.github.io/"/>
  <updated>2016-11-05T19:03:34+01:00</updated>
  <id>http://gabll.github.io/</id>
  <author>
    <name><![CDATA[Gabll]]></name>
    <email><![CDATA[gitgab@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Monitoring traffic jams, an easy way]]></title>
    <link href="http://gabll.github.io/blog/2016/08/31/monitoring-road-traffic/"/>
    <updated>2016-08-31T01:30:47+02:00</updated>
    <id>http://gabll.github.io/blog/2016/08/31/monitoring-road-traffic</id>
    <content type="html"><![CDATA[<p>My <a href="https://en.wikipedia.org/wiki/Chioggia">hometown</a> is a touristic island on the seaside near to the beach. There is only one bridge that connects it to the mainland, and it means that traffic is a nightmare during summer, with frequent and annoying jams.</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/jam_meme.jpg" width="200" alt="jam_meme" /></p>

<p>Jam hours depend on a lot of circumstances (weekday, traffic flow dynamics, weather, etc) and they seem to be nearly unpredictable. Well, I felt that I had to do something about it. I wanted to know at least <strong>how much</strong> traffic there is now, if is increasing or not, and its typical variation within the day.</p>

<p>It was definitely a topic for a small passion project during work vacation, so I&rsquo;ve built a small mobile app in Flask to help drivers understand whether or not put themselves on the road. I called it <a href="https://github.com/gabll/RomeaJam">RomeaJam</a>:</p>

<p style="text-align:center;"><a href="http://www.romeajam.com/"><img src="http://gabll.github.io/images/romeajam_screenshot.png" width="350" alt="Screenshot" /></a></p>

<p>This little project led me to learn some cool Python stuff:</p>

<ul>
<li><p>ORMs: <a href="http://www.sqlalchemy.org/">SQLAlchemy</a> was a revelation - I always desired an abstraction level that could handle classes without writing raw SQL!</p></li>
<li><p>Flask packages: <a href="http://flask.pocoo.org/">Flask</a> is growing very fast, and there is an ecosystem of packages for doing literally everything (<a href="https://github.com/viniciuschiele/flask-apscheduler">scheduling jobs</a>, <a href="http://flask-sqlalchemy.pocoo.org/2.1/">manage SQLAlchemy</a>, <a href="http://pythonhosted.org/Flask-Track-Usage/">tracking app usage</a> on the server side without cookies, etc)</p></li>
<li><p><a href="http://flask.pocoo.org/docs/0.11/deploying/mod_wsgi/">Deploy Flask</a> to production: I used apache2 with a python <a href="https://virtualenv.pypa.io/en/stable/">virtualenv</a>, and I learned that it can be quite an hassle. I definitely have to try to <em>dokerize</em> it.</p></li>
</ul>


<p>I&rsquo;m also excited because in the next year I will have enough data for time series analysis and short term traffic predictions!</p>

<p><a href="https://github.com/gabll/RomeaJam">GitHub repository for this project</a></p>

<p><strong>UPDATE (2016-11-05):</strong> The months passed and my MySQL database is still increasing (2M rows!). I learned that an index rebuild with <code>mysqlcheck -Aa -uroot -p</code> can speed up querying time, but still the webapp became very slow (expecially on query with joins). During the winter it&rsquo;s not used, but in the next summer I will have to move old data to a different database, leaving only the last month available for the webapp.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A recommendation engine for restaurants based on online reviews]]></title>
    <link href="http://gabll.github.io/blog/2015/04/07/recommendation-restaurants/"/>
    <updated>2015-04-07T06:30:17+02:00</updated>
    <id>http://gabll.github.io/blog/2015/04/07/recommendation-restaurants</id>
    <content type="html"><![CDATA[<p>As always when you are experiencing a &ldquo;<a href="http://en.wikipedia.org/wiki/Flow_(psychology)#Components">flow condition</a>&rdquo;, I didin&rsquo;t realized that the <a href="http://www.thisismetis.com/">Metis Data Science Bootcamp</a> came to an end. During these intense weeks we deepened our knlowledge of statistics and machine learning, as well as design and data visualization, in a way that surely I wasn&rsquo;t expecting at the beginning.</p>

<p>In the last 4 weeks we covered &ldquo;Big Data&rdquo; topics like Hadoop, MapReduce, Hive, etc, while focusing on a final passion project. I worked on the design and development of a collaborative-filtering recommendation engine for restaurants based on user reviews.</p>

<p><strong>Scraping framework</strong>: I used <a href="http://scrapy.org/">Scrapy</a> and <a href="https://github.com/scrapinghub/splash">Splash</a> for rendering and sraping almost one million reviews of NYC restaurants. I found Scrapy a very robust and powerful tool for scraping, since it can manage concurrent requests and it can be easily integrated with javascript renderers like Splash.</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/framewk.png" width="500" alt="Framework" /></p>

<p>The basic idea underneath the <a href="http://en.wikipedia.org/wiki/Collaborative_filtering">collaborative-filtering</a> model is to look for similar users, find the restaurants that they liked and rank them.</p>

<p><strong>Similar users</strong>: after feature selection (I considered only restaurants and users with at least 5 reviews) and dimensionality reduction (using the <a href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_incremental_pca.html">IncrementalPCA</a> in the last version of sklearn - 0.16), I got a dense matrix in which similar users can be found with a <a href="http://scikit-learn.org/stable/modules/neighbors.html">nearest neighbors</a> algorithm, using a <a href="http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.correlation.html">correlation</a> distance metric (it permits to take in account different scoring attitudes between users, e.g. one user may give only scores from 3 to 5 stars and another only from 2 to 4).</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/rec.png" width="500" alt="Sim_users" /></p>

<p><strong>Recommendations</strong>: after getting the list of restaurants visited by the similar users, I developed a scoring method for preticting the number of stars. Based on a bayesian approach, it consists basically in updating a prior containing the overall stars smoothed by the total number of reviews for the restaurant with a posterior, i.e. the weighted average of the reviews of the similar users (where the weight takes in account the number of restaurants in common, the total reviews of the user and his number of helpful votes received).</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/formula.png" width="500" alt="Formula" /></p>

<p>The main tuning parameters of the model are k (the number of nearest users to consider), alpha (how many additional users to include in the prior) and beta (how many reviews a restaurant must have in order to consider the overall average stars reliable).</p>

<p><strong>User interface</strong>: Afer tuning the model, I created a web application using <a href="http://flask.pocoo.org/">Flask</a>, <a href="http://getbootstrap.com/">Boostrap</a> and other javascript packages like <a href="http://www.json2html.com/">json2html</a>, <a href="http://nicolasbize.com/magicsuggest/">magicsuggest</a> and <a href="http://davidstutz.github.io/bootstrap-multiselect/">multiselect</a>. While I already used Flask in a previous project, Bootstrap was a very nice surpise: it&rsquo;s modern, clean and easy to use - all features that makes it an ideal choice for rapid prototyping.</p>

<p>Here is the final version of the webapp: <strong><a href="http://www.restommendation.com">www.restommendation.com</a></strong></p>

<p style="text-align:center;"><a href="http://www.restommendation.com/"><img src="http://gabll.github.io/images/screen.png" width="500" alt="Screenshot" /></a></p>

<p>As next steps, I will try to make the app available also for other cities, as well as creating an online-training mechanism for improving the recommendations (like/don&rsquo;t like buttons).</p>

<p><a href="https://github.com/gabll/Metis-Kojak">GitHub repository for this project</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Applying clustering techniques on recipes and ingredients]]></title>
    <link href="http://gabll.github.io/blog/2015/03/08/clustering-recipes-and-ingredients/"/>
    <updated>2015-03-08T05:30:17+01:00</updated>
    <id>http://gabll.github.io/blog/2015/03/08/clustering-recipes-and-ingredients</id>
    <content type="html"><![CDATA[<p>In the last two weeks at the <a href="http://www.thisismetis.com">Metis Data Science Bootcamp</a> we dived into NoSQL databases and natural language processing (week 7), unsupervised learning algorithms (week 7-8), dimensionality reduction, topic modeling and similarity (week 8), while working on an individual project: I choose to apply unsupervised learning techniques for clustering text data.</p>

<p>Firstly, I used the <a href="http://developer.pearson.com/apis/pearson-kitchen-manager">Pearson Kitchen Manager API</a> for clustering almost 500 worldwide recipes basing on their ingredients. After applying several algorithms, I extracted the top keywords for some of the clusters and printed them in word clouds:</p>

<p style="text-align:center;"><a href="http://gabll.github.io/images/Rec_cluster_1.jpg"><img src="http://gabll.github.io/images/Rec_cluster_1.jpg" width="200" alt="Rec_cluster_1" /></a> <a href="http://gabll.github.io/images/Rec_cluster_1.jpg"><img src="http://gabll.github.io/images/Rec_cluster_2.jpg" width="200" alt="Rec_cluster_2" /></a> <a href="http://gabll.github.io/images/Rec_cluster_1.jpg"><img src="http://gabll.github.io/images/Rec_cluster_4.jpg" width="200" alt="Rec_cluster_4" /></a></p>

<p>Secondly, I switched to the <a href="http://developer.yummly.com">Yummly API</a> for clustering ingredients on 17,000 Italian recipes from 1,000 blogs and kitchen websites. This time, the basic idea underneath ingredients clustering was to extract a bunch of not-too-rare and not-too-common ingredients, so I selected 71 ingredients with the help of a variance threshold. Then I built a <em>relationship matrix</em> between these ingredients using different scoring methods (jaccard similarity, joint probability score, etc). After trying some combinations of clustering algorithms and input matrices, I put one of the results in this <a href="http://gabll.github.io/blog/ingredients_clustering.html">d3 visualization</a>:</p>

<p style="text-align:center;"><a href="http://gabll.github.io/blog/ingredients_clustering.html"><img src="http://gabll.github.io/images/ingredients.png" alt="Metis-McNulty" /></a></p>

<p>As we should expect, items like <em>(yeast, flour, milk)</em> or <em>(mozzarella, tomato sauce, pizza doughs)</em> are grouped together, and the clusters themselves can help while compiling a shopping list.</p>

<p>At the end, I learned that tuning a clustering algorithm is more an art than a science: you need to explore not conventional approaches and combine different techniques basing on your intuition and the specific question you are trying to answer.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Decision support system for bank marketing calls]]></title>
    <link href="http://gabll.github.io/blog/2015/02/22/decision-support-system-for-bank-marketing-calls/"/>
    <updated>2015-02-22T16:23:17+01:00</updated>
    <id>http://gabll.github.io/blog/2015/02/22/decision-support-system-for-bank-marketing-calls</id>
    <content type="html"><![CDATA[<p>In these weeks at the <a href="http://www.thisismetis.com">Metis Data Science Bootcamp</a> we covered SQL on cloud servers (week 4), supervised learning algorithms with <a href="http://scikit-learn.org/">sklearn</a> and <a href="http://statsmodels.sourceforge.net/">statsmodels</a> (week 4-5), classification errors (week 5), interactive visualization and <a href="http://d3js.org/">d3.js</a> (week 6).</p>

<p>As a connecting fil rouge, we also worked on a individual project. I used <a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">this public dataset</a> from the University of California containing data about bank marketing calls for a short term deposit subscription.</p>

<p>My initial goal was to build a classifier in order to understand the probability of subscription given a set of features about the clients (age, job, marital status, etc), the  economic context (euribor rate, unemployment, etc) and the performances of the previous marketing campaigns (days from the last contact, previous campaign result, etc).<br/>
At the end, I chose a logistic regression model for its performance in terms of precision and recall.</p>

<p>Then, as my first d3 project, I focused on creating a day-to-day <a href="http://gabll.github.io/blog/bank-dss-mvp.html">dashboard</a> for the bank employees that could help them to address the marketing calls to the right clients in the right day.<br/>
The interface of this decision support system is quite simple: given some inputs about the current day and the economic indicators, it shows the customers sorted by their short term deposit subscription probability, with the ability to look for further details about the specific client.</p>

<p style="text-align:center;"><a href="http://gabll.github.io/blog/bank-dss-mvp.html"><img src="http://gabll.github.io/images/bank-dss.png" alt="Metis-McNulty" /></a></p>

<p>Some lessons learned during this project: feature selection and model evaluation require a deep understanding of the underlying math and the tools used, and visualization can take the same (or even more) amount of time of cleaning and preparing the data.</p>

<p><a href="https://github.com/gabll/Metis-McNulty">Github repository of this project</a></p>

<p><em>Update (02/24/2015):</em> I moved the logistic regression model to Python (instead of including it in the web page with javascript) using the <a href="http://flask.pocoo.org/">Flask</a> package: <a href="http://104.236.210.23:8000/">live demo here</a>. The response of the server can be a bit slower, but in this way it will be easier in the future to create a model with online training from the user inputs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Customizing IPython notebook]]></title>
    <link href="http://gabll.github.io/blog/2015/02/15/customizing-ipython-notebook/"/>
    <updated>2015-02-15T23:30:42+01:00</updated>
    <id>http://gabll.github.io/blog/2015/02/15/customizing-ipython-notebook</id>
    <content type="html"><![CDATA[<p><a href="http://ipython.org/notebook.html">IPhython notebook</a> is a very popular platform for coding and sharing projects in Python. Only recently I found a lot of official and unofficial extensions for improving its usability. Among them, I installed the following:</p>

<ol>
<li><a href="https://github.com/ipython-contrib/IPython-notebook-extensions/wiki/Comment-uncomment">Comment-uncomment</a>: this extension creates the shortcut <code>alt+C</code> for commenting code blocks (in the case you have a not-American keyboard and the standard <code>(cmd|ctrl)-/</code> doesn&rsquo;t work)</li>
<li><a href="https://github.com/sjpfenninger/ipython-extensions#notebook-theme-toggle">Theme toggle</a>: it creates a shortcut for toogle the css theme (I chose the <a href="https://github.com/nsonnad/base16-ipython-notebook#ocean-dark">ocean dark</a> one).</li>
<li><a href="https://github.com/sjpfenninger/ipython-extensions#notebook-web-notifications">Notify</a>: tired of checking if the kernel is still busy? This extension enables custom browser notifications for when the kernel becomes finally idle.</li>
<li><a href="https://github.com/ipython-contrib/IPython-notebook-extensions/wiki/aspell">Calico-spell-check</a>: it creates a toolbar button for spell checking in the markdown cells.</li>
</ol>


<p>Moreover, it&rsquo;s possible to enable retina resolution on matplotlib graphs by changing the <code>c.InlineBackend.figure_formats</code> value in the iphyton notebook config file (usually in ~/.iphyton/profile_default/ipython_notebook_config.py), and remove the space-consuming header of the page by adding <code>div#header {display: none !important;}</code> to the custom.css file.</p>

<p>Final note: in order to work together, it&rsquo;s important to load the extensions in the right oder. Here is how I load them in my <code>custom.js</code> file:</p>

<pre><code>require(["base/js/events"], function (events) {
$([IPython.events]).on("app_initialized.NotebookApp", function () {
    IPython.load_extensions('comment-uncomment');
    IPython.load_extensions('theme_toggle');
    });
});

IPython.load_extensions('notify');
IPython.load_extensions('calico-spell-check');

require(["nbextensions/theme_toggle"], function (theme_toggle) {
    $([IPython.events]).on("notebook_loaded.Notebook", theme_toggle.theme_toggle_shortcut);
});
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Project Luther: web scraping and linear regression on box office movies data]]></title>
    <link href="http://gabll.github.io/blog/2015/02/01/project-luter-web-scraping-and-linear-regression-on-box-office-movies-data/"/>
    <updated>2015-02-01T22:14:46+01:00</updated>
    <id>http://gabll.github.io/blog/2015/02/01/project-luter-web-scraping-and-linear-regression-on-box-office-movies-data</id>
    <content type="html"><![CDATA[<p>Last two weeks at the <a href="http://www.thisismetis.com/data-science">Metis Data Science Bootcamp</a> were quite intense. We learned the basics of web scraping with two interesting and powerful Python packages, <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> and <a href="https://code.google.com/p/selenium/">Selenium</a>, how to analyze and manipulate dataframes with <a href="http://pandas.pydata.org/">Pandas</a> and theory/applications of linear regression models.<br/>
At the end, we developed and presented to the class an individual project based on &ldquo;movies data&rdquo;. Everyone tried to answer a different question, from predicting success of movies based on tv series to understanding the key factors that determine the success of trilogies. My project was about predicting the box office opening income during the first weekend and determing the additional opening revenues in case of changing the release season given the genre.</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/model1.png" alt="Predicting opening income" /></p>

<p>A couple of lessons learnt: production budget and number of opening theaters play a important role in predicting the opening income, and sometimes the holiday season doesn&rsquo;t represent the &ldquo;best season&rdquo; in case of comedy or action films.</p>

<p>More insights in <a href="https://github.com/gabll/Metis-Luther/blob/master/Project_Luther_rev06.pdf">this presentation</a>; web scraping scripts and linear regression analysis in this <a href="https://github.com/gabll/Metis-Luther.git">GitHub repository</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello world!]]></title>
    <link href="http://gabll.github.io/blog/2015/01/12/first-post/"/>
    <updated>2015-01-12T21:49:47+01:00</updated>
    <id>http://gabll.github.io/blog/2015/01/12/first-post</id>
    <content type="html"><![CDATA[<p>First day at the <a href="http://www.thisismetis.com/">Metis Data Science Bootcamp</a>! We started with an interesting icebreaker game, the <a href="http://datascopeanalytics.com/what-we-think/2014/09/18/hipster-classifier-icebreaker">hipster classifier</a>, and setting up the developing environment for the next weeks (GitHub, Python packages, etc). And as a consequence of this, my first blog post!</p>

<p>This blog is hosted by <a href="https://pages.github.com/">GitHub pages</a>, using <a href="http://octopress.org/">Octopress</a> as a framework for generating static content. Basically, you have a repository in your computer cloned from GitHub, with a subdirectory where you can put all your blog post files written with the <a href="http://en.wikipedia.org/wiki/Markdown">markdown markup language</a>. Two simple commands, <code>rake generate</code> and <code>rake deploy</code>, will turn the markdown files in real HTML pages and push them into your GitHub hosting service.<br/>
Personalising template and layout is quite time consuming, but there is no need to edit css or scripts.</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/octopress_github.png" alt="Github pages - Octopress" /></p>
]]></content>
  </entry>
  
</feed>
