<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[gabll blog]]></title>
  <link href="http://gabll.github.io/atom.xml" rel="self"/>
  <link href="http://gabll.github.io/"/>
  <updated>2015-03-08T18:22:38-04:00</updated>
  <id>http://gabll.github.io/</id>
  <author>
    <name><![CDATA[Gabll]]></name>
    <email><![CDATA[gitgab@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Applying clustering techniques on recipes and ingredients]]></title>
    <link href="http://gabll.github.io/blog/2015/03/07/clustering-recipes-and-ingredients/"/>
    <updated>2015-03-07T23:30:17-05:00</updated>
    <id>http://gabll.github.io/blog/2015/03/07/clustering-recipes-and-ingredients</id>
    <content type="html"><![CDATA[<p>In the last two weeks at the <a href="http://www.thisismetis.com">Metis Data Science Bootcamp</a> we dived into NoSQL databases and natural language processing (week 7), unsupervised learning algorithms (week 7-8), dimensionality reduction, topic modeling and similarity (week 8), while working on an individual project: I choose to apply unsupervised learning techniques for clustering text data.</p>

<p>Firstly, I used the <a href="http://developer.pearson.com/apis/pearson-kitchen-manager">Pearson Kitchen Manager API</a> for clustering almost 500 worldwide recipes basing on their ingredients. After applying several algorithms, I extracted the top keywords for some of the clusters and printed them in word clouds:</p>

<p style="text-align:center;"><a href="http://gabll.github.io/images/Rec_cluster_1.jpg"><img src="http://gabll.github.io/images/Rec_cluster_1.jpg" width="200" alt="Rec_cluster_1" /></a> <a href="http://gabll.github.io/images/Rec_cluster_1.jpg"><img src="http://gabll.github.io/images/Rec_cluster_2.jpg" width="200" alt="Rec_cluster_2" /></a> <a href="http://gabll.github.io/images/Rec_cluster_1.jpg"><img src="http://gabll.github.io/images/Rec_cluster_4.jpg" width="200" alt="Rec_cluster_4" /></a></p>

<p>Secondly, I switched to the <a href="http://developer.yummly.com">Yummly API</a> for clustering ingredients on 17,000 Italian recipes from 1,000 blogs and kitchen websites. This time, the basic idea underneath ingredients clustering was to extract a bunch of not-too-rare and not-too-common ingredients, so I selected 71 ingredients with the help of a variance threshold. Then I built a <em>relationship matrix</em> between these ingredients using different scoring methods (jaccard similarity, joint probability score, etc). After trying some combinations of clustering algorithms and input matrices, I put one of the results in this <a href="http://gabll.github.io/blog/ingredients_clustering.html">d3 visualization</a>:</p>

<p style="text-align:center;"><a href="http://gabll.github.io/blog/ingredients_clustering.html"><img src="http://gabll.github.io/images/ingredients.png" alt="Metis-McNulty" /></a></p>

<p>As we should expect, items like <em>(yeast, flour, milk)</em> or <em>(mozzarella, tomato sauce, pizza doughs)</em> are grouped together, and the clusters themselves can help while compiling a shopping list.</p>

<p>At the end, I learned that tuning a clustering algorithm is more an art than a science: you need to explore not conventional approaches and combine different techniques basing on your intuition and the specific question you are trying to answer.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Decision support system for bank marketing calls]]></title>
    <link href="http://gabll.github.io/blog/2015/02/22/decision-support-system-for-bank-marketing-calls/"/>
    <updated>2015-02-22T10:23:17-05:00</updated>
    <id>http://gabll.github.io/blog/2015/02/22/decision-support-system-for-bank-marketing-calls</id>
    <content type="html"><![CDATA[<p>In these weeks at the <a href="http://www.thisismetis.com">Metis Data Science Bootcamp</a> we covered SQL on cloud servers (week 4), supervised learning algorithms with <a href="http://scikit-learn.org/">sklearn</a> and <a href="http://statsmodels.sourceforge.net/">statsmodels</a> (week 4-5), classification errors (week 5), interactive visualization and <a href="http://d3js.org/">d3.js</a> (week 6).</p>

<p>As a connecting fil rouge, we also worked on a individual project. I used <a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">this public dataset</a> from the University of California containing data about bank marketing calls for a short term deposit subscription.</p>

<p>My initial goal was to build a classifier in order to understand the probability of subscription given a set of features about the clients (age, job, marital status, etc), the  economic context (euribor rate, unemployment, etc) and the performances of the previous marketing campaigns (days from the last contact, previous campaign result, etc).<br/>
At the end, I chose a logistic regression model for its performance in terms of precision and recall.</p>

<p>Then, as my first d3 project, I focused on creating a day-to-day <a href="http://gabll.github.io/blog/bank-dss-mvp.html">dashboard</a> for the bank employees that could help them to address the marketing calls to the right clients in the right day.<br/>
The interface of this decision support system is quite simple: given some inputs about the current day and the economic indicators, it shows the customers sorted by their short term deposit subscription probability, with the ability to look for further details about the specific client.</p>

<p style="text-align:center;"><a href="http://gabll.github.io/blog/bank-dss-mvp.html"><img src="http://gabll.github.io/images/bank-dss.png" alt="Metis-McNulty" /></a></p>

<p>Some lessons learned during this project: feature selection and model evaluation require a deep understanding of the underlying math and the tools used, and visualization can take the same (or even more) amount of time of cleaning and preparing the data.</p>

<p><a href="https://github.com/gabll/Metis-McNulty">Github repository of this project</a></p>

<p><em>Update (02/24/2015):</em> I moved the logistic regression model to Python (instead of including it in the web page with javascript) using the <a href="http://flask.pocoo.org/">Flask</a> package: <a href="http://104.236.210.23:8000/">live demo here</a>. The response of the server can be a bit slower, but in this way it will be easier in the future to create a model with online training from the user inputs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Customizing IPython notebook]]></title>
    <link href="http://gabll.github.io/blog/2015/02/15/customizing-ipython-notebook/"/>
    <updated>2015-02-15T17:30:42-05:00</updated>
    <id>http://gabll.github.io/blog/2015/02/15/customizing-ipython-notebook</id>
    <content type="html"><![CDATA[<p><a href="http://ipython.org/notebook.html">IPhython notebook</a> is a very popular platform for coding and sharing projects in Python. Only recently I found a lot of official and unofficial extensions for improving its usability. Among them, I installed the following:</p>

<ol>
<li><a href="https://github.com/ipython-contrib/IPython-notebook-extensions/wiki/Comment-uncomment">Comment-uncomment</a>: this extension creates the shortcut <code>alt+C</code> for commenting code blocks (in the case you have a not-American keyboard and the standard <code>(cmd|ctrl)-/</code> doesn&rsquo;t work)</li>
<li><a href="https://github.com/sjpfenninger/ipython-extensions#notebook-theme-toggle">Theme toggle</a>: it creates a shortcut for toogle the css theme (I chose the <a href="https://github.com/nsonnad/base16-ipython-notebook#ocean-dark">ocean dark</a> one).</li>
<li><a href="https://github.com/sjpfenninger/ipython-extensions#notebook-web-notifications">Notify</a>: tired of checking if the kernel is still busy? This extension enables custom browser notifications for when the kernel becomes finally idle.</li>
<li><a href="https://github.com/ipython-contrib/IPython-notebook-extensions/wiki/aspell">Calico-spell-check</a>: it creates a toolbar button for spell checking in the markdown cells.</li>
</ol>


<p>Moreover, it&rsquo;s possible to enable retina resolution on matplotlib graphs by changing the <code>c.InlineBackend.figure_formats</code> value in the iphyton notebook config file (usually in ~/.iphyton/profile_default/ipython_notebook_config.py), and remove the space-consuming header of the page by adding <code>div#header {display: none !important;}</code> to the custom.css file.</p>

<p>Final note: in order to work together, it&rsquo;s important to load the extensions in the right oder. Here is how I load them in my <code>custom.js</code> file:</p>

<pre><code>require(["base/js/events"], function (events) {
$([IPython.events]).on("app_initialized.NotebookApp", function () {
    IPython.load_extensions('comment-uncomment');
    IPython.load_extensions('theme_toggle');
    });
});

IPython.load_extensions('notify');
IPython.load_extensions('calico-spell-check');

require(["nbextensions/theme_toggle"], function (theme_toggle) {
    $([IPython.events]).on("notebook_loaded.Notebook", theme_toggle.theme_toggle_shortcut);
});
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Project Luther: web scraping and linear regression on box office movies data]]></title>
    <link href="http://gabll.github.io/blog/2015/02/01/project-luter-web-scraping-and-linear-regression-on-box-office-movies-data/"/>
    <updated>2015-02-01T16:14:46-05:00</updated>
    <id>http://gabll.github.io/blog/2015/02/01/project-luter-web-scraping-and-linear-regression-on-box-office-movies-data</id>
    <content type="html"><![CDATA[<p>Last two weeks at the <a href="http://www.thisismetis.com/data-science">Metis Data Science Bootcamp</a> were quite intense. We learned the basics of web scraping with two interesting and powerful Python packages, <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> and <a href="https://code.google.com/p/selenium/">Selenium</a>, how to analyze and manipulate dataframes with <a href="http://pandas.pydata.org/">Pandas</a> and theory/applications of linear regression models.<br/>
At the end, we developed and presented to the class an individual project based on &ldquo;movies data&rdquo;. Everyone tried to answer a different question, from predicting success of movies based on tv series to understanding the key factors that determine the success of trilogies. My project was about predicting the box office opening income during the first weekend and determing the additional opening revenues in case of changing the release season given the genre.</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/model1.png" alt="Predicting opening income" /></p>

<p>A couple of lessons learnt: production budget and number of opening theaters play a important role in predicting the opening income, and sometimes the holiday season doesn&rsquo;t represent the &ldquo;best season&rdquo; in case of comedy or action films.</p>

<p>More insights in <a href="https://github.com/gabll/Metis-Luther/blob/master/Project_Luther_rev06.pdf">this presentation</a>; web scraping scripts and linear regression analysis in this <a href="https://github.com/gabll/Metis-Luther.git">GitHub repository</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello world!]]></title>
    <link href="http://gabll.github.io/blog/2015/01/12/first-post/"/>
    <updated>2015-01-12T15:49:47-05:00</updated>
    <id>http://gabll.github.io/blog/2015/01/12/first-post</id>
    <content type="html"><![CDATA[<p>First day at the <a href="http://www.thisismetis.com/">Metis Data Science Bootcamp</a>! We started with an interesting icebreaker game, the <a href="http://datascopeanalytics.com/what-we-think/2014/09/18/hipster-classifier-icebreaker">hipster classifier</a>, and setting up the developing environment for the next weeks (GitHub, Python packages, etc). And as a consequence of this, my first blog post!</p>

<p>This blog is hosted by <a href="https://pages.github.com/">GitHub pages</a>, using <a href="http://octopress.org/">Octopress</a> as a framework for generating static content. Basically, you have a repository in your computer cloned from GitHub, with a subdirectory where you can put all your blog post files written with the <a href="http://en.wikipedia.org/wiki/Markdown">markdown markup language</a>. Two simple commands, <code>rake generate</code> and <code>rake deploy</code>, will turn the markdown files in real HTML pages and push them into your GitHub hosting service.<br/>
Personalising template and layout is quite time consuming, but there is no need to edit css or scripts.</p>

<p style="text-align:center;"><img src="http://gabll.github.io/images/octopress_github.png" alt="Github pages - Octopress" /></p>
]]></content>
  </entry>
  
</feed>
